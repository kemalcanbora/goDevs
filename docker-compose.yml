version: '3'
services:
  zoo:
    image: zookeeper:3.4.9
    restart: on-failure
    hostname: zoo1
    ports:
      - "2189:2189"
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2189
      ZOO_SERVERS: server.1=zoo1:2888:3888
    networks:
      - esnet
  kafka:
    image: confluentinc/cp-kafka:4.1.0
    hostname: kafka1
    restart: on-failure
    ports:
      - "9092:9092"
    environment:
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
      # add the entry "127.0.0.1    kafka1" to your /etc/hosts file
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2189"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zoo
    networks:
      - esnet
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.9.0
    container_name: qa_elasticsearch
    hostname: elasticsearch
    restart: on-failure
    environment:
      - discovery.type=single-node
      - ES_DATA_DIR=/data/es/db
      - ELASTIC_PASSWORD=$DOCKER_ES_PASSWORD
      - xpack.security.enabled=$DOCKER_ELASTIC_SECURITY
    healthcheck:
      test: "curl http://0.0.0.0:9200"
      interval: "1s"
      timeout: "3s"
      retries: 60
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - es_data_volume:/data/es/db
    ports:
      - 9200:9200
    networks:
      - esnet
  logstash:
    image: docker.elastic.co/logstash/logstash:7.9.0
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logstash/pipeline:/usr/share/logstash/pipeline
      - ./logstash/pipelines.yml:/usr/share/logstash/pipelines.yml:ro
    ports:
      - "5000:5000"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
      ELASTIC_PASSWORD: $DOCKER_ES_PASSWORD
    depends_on:
      - elasticsearch
    networks:
      - esnet
volumes:
  es_data_volume:
    driver: local

networks:
  esnet: